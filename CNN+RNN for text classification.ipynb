{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f056b4ff"
   },
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "73b47510",
    "outputId": "28d7ed83-92ab-4951-de7e-79679cc41ee6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version information\n",
      "python: 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]\n",
      "numpy: 1.21.6\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "import re\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import torchtext\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "torch.manual_seed(10)\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import gzip\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "print('Version information')\n",
    "\n",
    "print('python: {}'.format(sys.version))\n",
    "print('numpy: {}'.format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eff26cb3"
   },
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "837cc1e5"
   },
   "source": [
    "We start by loading both data sets already split into an 80/20 train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "e2b97025",
    "outputId": "391ea7e2-f53d-40d4-cd91-d7989f239c7e"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15f2a21c"
   },
   "source": [
    "Below is the number of headlines in the train and test set as well as a sample of the article headlines and its binary label, where 0 is considered not clickbait and 1 is clickbait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "11e3ebf5",
    "outputId": "97c351fe-624d-4b6c-b8e2-1cf03ad30dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Headlines: 19200\n",
      "Number of Test Headlines: 4800\n",
      "\n",
      "\n",
      "Sample Label and Headlines:\n",
      "1: 27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\n",
      "\n",
      "1: 22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\n",
      "\n",
      "0: PepsiCo Profit Falls 43 Percent\n",
      "\n",
      "0: Website of Bill O'Reilly, FOX News commentator, hacked in retribution\n",
      "\n",
      "1: The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\n",
      "\n",
      "\n",
      "Output of Sample Headlines without Print Statement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\\n',\n",
       " \"22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\\n\",\n",
       " 'PepsiCo Profit Falls 43 Percent\\n',\n",
       " \"Website of Bill O'Reilly, FOX News commentator, hacked in retribution\\n\",\n",
       " 'The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Number of Train Headlines: {len(x_train)}')\n",
    "print(f'Number of Test Headlines: {len(x_test)}')\n",
    "\n",
    "print('\\n\\nSample Label and Headlines:')\n",
    "x = 105\n",
    "for label, line in zip(y_train[x:x+5], x_train[x:x+5]):\n",
    "    print(f'{label}: {line}')\n",
    "    \n",
    "print('\\nOutput of Sample Headlines without Print Statement:')\n",
    "x_train[x:x+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "20a8debc",
    "outputId": "2d934897-8f6f-49bb-a85c-d627017dd8b0"
   },
   "outputs": [],
   "source": [
    "df_train_wos = pd.read_csv('./data/train_wos.csv')\n",
    "df_test_wos = pd.read_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])\n",
    "\n",
    "# Numerical label to domain mapping\n",
    "wos_label = {0:'CS', 1:'ECE', 2:'Civil', 3:'Medical'}\n",
    "# Numerical label to Numerical mapping\n",
    "label_mapping = {0:0, 1:1, 4:2, 5:3}\n",
    "\n",
    "for i, label in enumerate(y_train_wos):\n",
    "    y_train_wos[i] = label_mapping[label]\n",
    "for i, label in enumerate(y_test_wos):\n",
    "    y_test_wos[i] = label_mapping[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "d24ac5b6",
    "outputId": "f5df643b-a8d5-41de-cba7-eede9bbaa59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Articles: 1600\n",
      "Number of Test Articles: 400\n",
      "\n",
      "Label Key: {0: 'CS', 1: 'ECE', 2: 'Civil', 3: 'Medical'}\n",
      "\n",
      "Sample Label and Articles:\n",
      "\n",
      "0 - CS: An efficient procedure for calculating the electromagnetic fields in multilayered cylindrical structures is reported in this paper. Using symbolic computation, spectral Green's functions, suitable for numerical implementations are determined in compact and closed forms. Applications are presented for structures with two dielectric layers.\n",
      "\n",
      "1 - ECE: A multifunctional platform based on the microhotplate was developed for applications including a Pirani vacuum gauge, temperature, and gas sensor. It consisted of a tungsten microhotplate and an on-chip operational amplifier. The platform was fabricated in a standard complementary metal oxide semiconductor (CMOS) process. A tungsten plug in standard CMOS process was specially designed as the serpentine resistor for the microhotplate, acting as both heater and thermister. With the sacrificial layer technology, the microhotplate was suspended over the silicon substrate with a 340 nm gap. The on-chip operational amplifier provided a bias current for the microhotplate. This platform has been used to develop different kinds of sensors. The first one was a Pirani vacuum gauge ranging from 10(-1) to 10(5) Pa. The second one was a temperature sensor ranging from -20 to 70 degrees C. The third one was a thermal-conductivity gas sensor, which could distinguish gases with different thermal conductivities in constant gas pressure and environment temperature. In the fourth application, with extra fabrication processes including the deposition of gas-sensitive film, the platform was used as a metal-oxide gas sensor for the detection of gas concentration.\n",
      "\n",
      "2 - Civil: Artificial neural networks have been effectively used in various civil engineering fields, including construction management and labour productivity. In this study, the performance of the feed forward neural network (FFNN) was compared with radial basis neural network (RBNN) in modelling the productivity of masonry crews. A variety of input factors were incorporated and analysed. Mean absolute percentage error (MAPE) and correlation coefficient (R) were used to evaluate model performance. Research results indicated that the neural computing techniques could be successfully employed in modelling crew productivity. It was also found that successful models could be developed with different combinations of input factors, and several of the models which excluded one or more input factors turned out to be better than the baseline models. Based on the MAPE values obtained for the models, the RBNN technique was found to be better than the FFNN technique, although both slightly overestimated the masons' productivity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Train Articles: {len(x_train_wos)}')\n",
    "print(f'Number of Test Articles: {len(x_test_wos)}')\n",
    "\n",
    "print('\\nLabel Key:', wos_label)\n",
    "\n",
    "print('\\nSample Label and Articles:\\n')\n",
    "x = 107\n",
    "for label, line in zip(y_train_wos[x:x+3], x_train_wos[x:x+3]):\n",
    "    print(f'{label} - {wos_label[label]}: {line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use truncated SVD to project the learned word2vec embedding to 2D space for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iLhTgwE183xt",
    "outputId": "832755ed-5da8-47b4-eb4a-41d15f938d65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "w2v.word2idx[''] = 0\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W2_dec = svd.fit_transform(embeddings)\n",
    "\n",
    "x = W2_dec[:,0]\n",
    "y = W2_dec[:,1]\n",
    "plot = sns.scatterplot(x=x, y=y)\n",
    "\n",
    "for i in range(0,W2_dec.shape[0]):\n",
    "     plot.text(x[i], y[i]+2e-2, list(w2v.word2idx)[i], horizontalalignment='center', size='small', color='black', weight='semibold');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will look into the learned property of the word2vec embedding. Warsaw is the capital of Poland and we now calculate the difference between embeddings of \"warsaw\" and \"poland\". After that, we add the difference to the embedding of \"paris\". We then rank the dot product of the computed embedding vs all the embeddings. Notice that the larger this value, the more similar two embeddings are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "6Opu7Awy979w",
    "outputId": "058539e5-171d-4c34-b086-5a283fc82684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poland: 0.682\n",
      "paris: 0.535\n",
      "germany: 0.404\n",
      "france: 0.353\n",
      "woman: 0.275\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeddings[w2v.word2idx[\"poland\"]]\n",
    "emb2 = embeddings[w2v.word2idx[\"warsaw\"]]\n",
    "emb3 = embeddings[w2v.word2idx[\"paris\"]]\n",
    "\n",
    "emb4 = emb1 - emb2 + emb3\n",
    "emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n",
    "emb4 = emb4 / emb4_norm\n",
    "\n",
    "emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "for word_id in top5:\n",
    "    print(\"{}: {:.3f}\".format(w2v.idx2word[word_id], dists[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqJwpMAYUg4A"
   },
   "source": [
    "Ideally with large amount of data, we should have got france as the most nearest word. But depending on the implementation and amount of data, it can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRvybL9rYxcQ"
   },
   "source": [
    "## Classification with CNN\n",
    "\n",
    "Convolutional layers are used to find patterns by sliding small kernel window over input. Instead of multiplying the filters on the small regions of the images, it slides through embedding vectors of few words as mentioned by window size. For looking at sequences of word embeddings, the window has to look at multiple word embeddings in a sequence. They will be rectangular with size window_size * embedding_size. For example, if window size is 3 then kernel will be 3*500. This essentially represents n-grams in the model. The kernel weights (filter) are multiplied to word embeddings in pairs and summed up to get output values. As the network is being learned, these kernel weights are also being learned.\n",
    "\n",
    "We will be using convolutional network with pre-trained word2vec models for classification. We implement a convolutional neural network for text classification similar to the CNN-rand baseline described by [Kim (2014)](https://aclanthology.org/D14-1181.pdf). We use pre-trained word2vec models for feasibility of finding appropriate embeddings. The architecture of our model looks like :\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cezannec.github.io/assets/cnn_text/complete_text_classification_CNN.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "We will be using an Embedding layer loaded with a word2vec model, followed by a convolution layer, and a linear layer.\n",
    "\n",
    "We will would be using the Clickbait and Web of science dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlQWYkt6bjPM"
   },
   "source": [
    "### 2.1.1 : Pre-Processing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "QtXq7iy3bwrs",
    "outputId": "e4849779-987a-4a07-d1bb-c4cb867814bc"
   },
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def preprocess(data):\n",
    "    preprocessed_data = []\n",
    "    for text in data:\n",
    "        tokens = simple_preprocess(text, deacc=True)\n",
    "        preprocessed_data.append(tokens)\n",
    "    return preprocessed_data\n",
    "\n",
    "preprocessed_x_train = preprocess(x_train)\n",
    "preprocessed_x_train_wos = preprocess(x_train_wos)\n",
    "\n",
    "preprocessed_x_test = preprocess(x_test)\n",
    "preprocessed_x_test_wos = preprocess(x_test_wos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "_M0alpCXcN3N",
    "outputId": "6ffd3641-ff5e-4366-958d-f18399a31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOr_wpjNdGnj"
   },
   "source": [
    "### 2.1.2 : Utility functions for training Word2Vec Model\n",
    "\n",
    "Run the below cells for making word2vec model, vectors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "3gjLdwNOdOYd",
    "outputId": "2315178e-7fd3-42bd-c555-8af5915f7976"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(data, padding=True, sg=1, min_count=1, size=500, workers=3, window=3):\n",
    "    data.append(['pad'])\n",
    "    w2v_model = Word2Vec(data, min_count = min_count, size = size, workers = workers, window = window, sg = sg)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DTUjqQnjdOUz",
    "outputId": "11051581-803c-477e-9788-af3d12a9e201"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_word2vec_vector(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel.wv.vocab:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel.wv.vocab[word].index\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "PrOTzz5gddgj",
    "outputId": "70681d17-e12c-44bd-8be2-fd7be0c7b8c9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_target(label):\n",
    "  return torch.tensor([label], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXuJ6ouncC8Z"
   },
   "source": [
    "## 2.2 : Classifying Clickbait Dataset using CNN\n",
    "\n",
    "Run the below cell to classify the Clickbait train and test dataset using the CNN functions already implemented in 2.\n",
    "\n",
    "An accuracy of more than 80% is acceptable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "lurnaUoUXCcU",
    "outputId": "dece0006-ceab-4123-cb16-7e728f2e6f3c"
   },
   "outputs": [],
   "source": [
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0517495 ,  0.02628629,  0.07220484, -0.03108063, -0.02587266,\n",
       "       -0.0301182 , -0.06114997, -0.02721459, -0.02983144,  0.05376582,\n",
       "        0.06676152, -0.0726303 ,  0.02780348, -0.03402811, -0.03466607,\n",
       "        0.01522685,  0.0019432 , -0.0558793 ,  0.03599539,  0.0414186 ,\n",
       "        0.04959976, -0.02714492,  0.05093278, -0.00703063, -0.01265506,\n",
       "       -0.05490255, -0.00043444,  0.03858402,  0.02700144,  0.02332128,\n",
       "        0.05327508, -0.03958281, -0.0066215 ,  0.00677643,  0.00272754,\n",
       "       -0.00031868,  0.00169334, -0.03721954, -0.05408469, -0.03118667,\n",
       "        0.00797785,  0.01963314, -0.00513649,  0.00493522, -0.04443372,\n",
       "       -0.00914803, -0.00841375, -0.00455312,  0.05230442,  0.03279027,\n",
       "       -0.00030661,  0.0113712 , -0.01001645, -0.02666881, -0.01318737,\n",
       "        0.01622818,  0.01851158,  0.00201129,  0.00134771,  0.00694489,\n",
       "       -0.01407568,  0.04534241, -0.02779939,  0.03252061, -0.0530932 ,\n",
       "       -0.04275605, -0.01937444,  0.02310384,  0.03537126, -0.04125426,\n",
       "       -0.00259803,  0.01419637, -0.05907422,  0.01535604,  0.01258114,\n",
       "        0.0266016 ,  0.00341209, -0.02205893,  0.01673181,  0.0107795 ,\n",
       "       -0.05348166, -0.0178931 ,  0.03125849, -0.00896124,  0.05657075,\n",
       "       -0.0380126 , -0.00071173,  0.0314774 ,  0.01169263,  0.0177978 ,\n",
       "        0.02752753,  0.00632816, -0.05396186,  0.01118466, -0.03775745,\n",
       "       -0.00175799, -0.02141193, -0.0481063 , -0.08398353,  0.03941395,\n",
       "        0.0226121 , -0.03493296,  0.00553395, -0.01602098, -0.04838488,\n",
       "        0.02183708,  0.0404371 ,  0.0164234 ,  0.00877307, -0.05370911,\n",
       "        0.02595229,  0.06879444, -0.02350329,  0.06721345,  0.01339201,\n",
       "       -0.03564365, -0.03030853, -0.01116478, -0.00866871, -0.00375022,\n",
       "        0.01097468, -0.01907361,  0.08339642,  0.00191025,  0.00709305,\n",
       "        0.06545453, -0.00722326, -0.03021956, -0.0199323 , -0.05776131,\n",
       "        0.02972094, -0.02037591,  0.01343417,  0.03361819, -0.03910689,\n",
       "       -0.02257541,  0.0212288 ,  0.00149282, -0.0230557 ,  0.00511271,\n",
       "       -0.01775068,  0.01330767, -0.00107191, -0.01170616, -0.03564465,\n",
       "        0.00601139,  0.01319172, -0.05087821,  0.0156967 ,  0.01831808,\n",
       "       -0.02559285, -0.01821694,  0.06333574, -0.03581272,  0.01042741,\n",
       "       -0.0465227 ,  0.00401696,  0.03121597, -0.04281478, -0.01323173,\n",
       "        0.02043187, -0.01041341, -0.04921925,  0.01145875,  0.05103969,\n",
       "        0.00108901,  0.02469981,  0.00237473, -0.01265817, -0.0185648 ,\n",
       "       -0.02571978, -0.00031106,  0.01317218, -0.00793751, -0.04483651,\n",
       "       -0.09643224, -0.08381069,  0.01103097, -0.0093814 ,  0.02879322,\n",
       "        0.03507671, -0.00365063, -0.00550556,  0.01225343,  0.01104255,\n",
       "        0.00729233,  0.01692401, -0.0360348 , -0.05728499, -0.04655408,\n",
       "       -0.04272651, -0.06637955,  0.00113346,  0.00891444,  0.00611955,\n",
       "       -0.00855054,  0.02336745, -0.04821976, -0.00231431,  0.01622348,\n",
       "       -0.03911808,  0.04057411, -0.0316153 , -0.04968289,  0.01422193,\n",
       "        0.04367048,  0.03434098, -0.02940818,  0.00738856,  0.01812571,\n",
       "       -0.04889746,  0.06042008,  0.0159962 , -0.02069619, -0.03454758,\n",
       "        0.01005222,  0.03204902,  0.02981389, -0.00772998,  0.01374867,\n",
       "        0.01136034, -0.00366996, -0.06738368,  0.05630082, -0.0135026 ,\n",
       "       -0.0151111 ,  0.01751779,  0.02575636, -0.04750144,  0.01194416,\n",
       "        0.00236691, -0.06608966, -0.00463366,  0.00151941, -0.01240201,\n",
       "        0.00339847,  0.03528943, -0.03890844, -0.05852772, -0.01381641,\n",
       "       -0.00512302, -0.05078643, -0.01867147,  0.00997548,  0.0779273 ,\n",
       "       -0.03848036,  0.00817498,  0.0475658 , -0.01419928,  0.00081751,\n",
       "       -0.02436608, -0.01474593,  0.03823642, -0.0380495 ,  0.03311285,\n",
       "       -0.04447369, -0.00314233,  0.0090479 , -0.0476016 ,  0.02427687,\n",
       "        0.02722426, -0.04379902,  0.03889974,  0.01482746,  0.01143239,\n",
       "       -0.07689106, -0.00952377,  0.01685673, -0.01497863, -0.0069141 ,\n",
       "        0.02246525, -0.01416477, -0.00320881,  0.01014744, -0.0080557 ,\n",
       "       -0.0243438 , -0.01273473,  0.00879614,  0.06344288, -0.03011584,\n",
       "        0.09417307,  0.01034036,  0.01073931,  0.00849997, -0.01753243,\n",
       "        0.00546011,  0.02125087,  0.03836306,  0.02873432,  0.03107642,\n",
       "       -0.0605531 ,  0.02296693, -0.03839615,  0.02156655,  0.00475547,\n",
       "        0.02735763,  0.00793967,  0.01544547, -0.01775333, -0.06468649,\n",
       "        0.01004397,  0.010897  , -0.00117476, -0.04585572,  0.01291281,\n",
       "        0.01411699,  0.00339964, -0.02648012,  0.0409902 ,  0.00753182,\n",
       "       -0.01067648,  0.00867125,  0.01803231, -0.03348063, -0.01500097,\n",
       "       -0.05097122,  0.02652386, -0.00362972, -0.00106054,  0.02355446,\n",
       "       -0.01605001, -0.00767642, -0.00931726, -0.00595148,  0.03620091,\n",
       "        0.03110594,  0.02354597,  0.00492417, -0.01127512, -0.00071935,\n",
       "       -0.0223239 , -0.01493562, -0.05415813, -0.0148317 ,  0.0366657 ,\n",
       "       -0.01928494,  0.00667596, -0.03001043,  0.07286509,  0.00768825,\n",
       "        0.04896691,  0.02884442,  0.01114896,  0.03521592, -0.01086847,\n",
       "       -0.0086736 ,  0.00385496,  0.02924124, -0.00250036,  0.01100219,\n",
       "        0.01481794,  0.05156141, -0.03666745, -0.03272676, -0.00401773,\n",
       "        0.00917159, -0.03654914, -0.00858639, -0.02313578,  0.02777149,\n",
       "       -0.00975655,  0.04242653,  0.06488148, -0.0256004 , -0.04224641,\n",
       "       -0.01535395, -0.05379586, -0.03580857, -0.04832366, -0.05167288,\n",
       "       -0.01147131, -0.00759035, -0.08807711, -0.06434526, -0.01368304,\n",
       "       -0.01399706,  0.02383025, -0.06694791,  0.01058841, -0.00672455,\n",
       "       -0.01237185, -0.01729774, -0.02168571,  0.06154042, -0.0317235 ,\n",
       "       -0.03474991, -0.02040479, -0.01070862, -0.05303867,  0.02957527,\n",
       "        0.06338792, -0.07152072, -0.01278913, -0.06113587, -0.01945976,\n",
       "        0.01422807, -0.01501234,  0.0114839 , -0.03471261,  0.00186693,\n",
       "       -0.0034151 ,  0.00506853, -0.02738232, -0.00398371, -0.01336092,\n",
       "        0.03305109, -0.0197486 , -0.00287821,  0.01139408, -0.0613923 ,\n",
       "       -0.02199463, -0.00745141, -0.06347657, -0.01160805,  0.03600858,\n",
       "        0.03430868, -0.05988412,  0.00629569,  0.01138872, -0.05041159,\n",
       "        0.00043246,  0.02375339, -0.03536749,  0.01080749,  0.05711877,\n",
       "        0.01384434,  0.00726811, -0.03107066, -0.01459971, -0.0539442 ,\n",
       "       -0.01902374,  0.04268318, -0.01215145, -0.04179751, -0.05437882,\n",
       "        0.08158334, -0.03989949, -0.02197054, -0.0144825 , -0.02559138,\n",
       "       -0.03615506,  0.00105588, -0.0053559 ,  0.00559968,  0.01361711,\n",
       "        0.06280945, -0.02621305,  0.04053844, -0.00278167,  0.01836349,\n",
       "       -0.04268743,  0.02183836,  0.02568047, -0.02698765,  0.01375899,\n",
       "       -0.0093976 ,  0.03116829,  0.0260072 ,  0.03325235,  0.03694078,\n",
       "       -0.00694142, -0.02393209,  0.00280771,  0.02681992, -0.04593961,\n",
       "       -0.01253042, -0.02816578, -0.05459666,  0.07918867, -0.01981594,\n",
       "        0.01217522, -0.02523132,  0.01703297, -0.02138513, -0.0249512 ,\n",
       "        0.01815369,  0.02929994, -0.00182424,  0.00472403,  0.01336053,\n",
       "        0.01836379,  0.00250601, -0.01583918,  0.01730475,  0.00305894,\n",
       "        0.00723423, -0.00091921, -0.04581764,  0.00443267,  0.022194  ,\n",
       "       -0.06451493,  0.02882269, -0.04755586, -0.02829822,  0.00316075,\n",
       "       -0.03662017, -0.02160181,  0.03200387, -0.02167094, -0.04831344],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv['pad']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because CNN requires the input data to be of the same length. We use the embedding of the \"pad\" word as the padding vector. Notice that this choice is just a convention and other tokens could also work for this purpose. In more complex language model, there will be a dedicated '\\<pad\\>' token for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MnRN7kn7XCe6",
    "outputId": "39df6412-550c-4e4c-c892-3473877470da"
   },
   "outputs": [],
   "source": [
    "max_sen_len = max(map(len, preprocessed_x_train))\n",
    "padding_idx = w2vmodel.wv.vocab['pad'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17099, 1, 500])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(w2vmodel.wv.vectors).type(torch.float32).unsqueeze(1).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zIdO6zAsUMGV",
    "outputId": "d7cce669-26ac-45cc-e11c-827cfd122925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss on epoch 0: 7294.662585\n",
      "1\n",
      "loss on epoch 1: 7120.011679\n",
      "2\n",
      "loss on epoch 2: 7078.914021\n",
      "3\n",
      "loss on epoch 3: 7043.359826\n",
      "4\n",
      "loss on epoch 4: 7016.684704\n"
     ]
    }
   ],
   "source": [
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    print(epoch)\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train[index])\n",
    "\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train[index])\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aOiTWeR6VDXk",
    "outputId": "b02e1d0d-5194-4b47-faec-cdba1a3b330f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using CNN : 0.942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index in range(len(y_test)):\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_test[index])\n",
    "        probs = model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        t = make_target(y_test[index]).cpu().numpy()[0]\n",
    "        original_lables_cnn.append(make_target(y_test[index]).cpu().numpy()[0])\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using CNN : {:.3f}\".format(accuracy_score(original_lables_cnn, cnn_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "Z1di5i2NwyXj",
    "outputId": "0280d9bb-cb4f-4f8b-ed85-606c5ab97b31"
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = np.asarray(cnn_predictions)\n",
    "\n",
    "with open('cnn_clickbait.pkl', 'wb') as fp:\n",
    "    pickle.dump(preds, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRXO38UrmQ18"
   },
   "source": [
    "## 2.3 : Classifying Web of Science Dataset using CNN\n",
    "\n",
    "Run the below cell to classify the WoS train and test dataset using the CNN functions implemented in 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XUyZvrX3mWXj",
    "outputId": "90050d4c-c393-483d-c76d-d7cc475e3ce7"
   },
   "outputs": [],
   "source": [
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train_wos, padding=True, sg=sg, min_count=min_count, size=size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "dP07m73fRM44",
    "outputId": "28f17390-69d5-4178-f8ec-9a51ae9dbaa6"
   },
   "outputs": [],
   "source": [
    "max_sen_len = max(map(len, preprocessed_x_train_wos))\n",
    "padding_idx = w2vmodel.wv.vocab['pad'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "HZPVaPsvmoDR",
    "outputId": "21294fa2-48a5-455e-c7fa-fd8d5d9c602f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss on epoch 0: 1960.494195\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "loss on epoch 5: 1588.307115\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "loss on epoch 10: 1498.507259\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "loss on epoch 15: 1449.376294\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train_wos)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    print(epoch)\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train_wos[index])\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train_wos[index])\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 0:    \n",
    "      print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E3bSg3HCYnIS",
    "outputId": "e47cc8c4-3846-46bc-f7b2-7120947e8263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using CNN : 0.635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index in range(len(y_test_wos)):\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_test_wos[index])\n",
    "        probs = model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        t = make_target(y_test_wos[index]).cpu().numpy()[0]\n",
    "        original_lables_cnn.append(make_target(y_test_wos[index]).cpu().numpy()[0])\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using CNN : {:.3f}\".format(accuracy_score(original_lables_cnn, cnn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "px4Og3agxxkY"
   },
   "source": [
    "Run the below cell to save the predictions. You will be required to upload the predictions on gradescope for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XwwCsXxux2nS",
    "outputId": "7b88e6a6-9122-4ed7-a223-c7892856f9b7"
   },
   "outputs": [],
   "source": [
    "preds = np.asarray(cnn_predictions)\n",
    "\n",
    "with open('cnn_wos.pkl', 'wb') as fp:\n",
    "    pickle.dump(preds, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJaO3vd_oP-Z"
   },
   "source": [
    "## Classification with RNN\n",
    "\n",
    "\n",
    "We will be using recurrent neural networks with pre-trained word2vec models for classification. We use pre-trained word2vec models for feasibility of finding appropriate embeddings. The architecture of our model looks like :\n",
    "\n",
    "<p align=\"center\"><img src=\"https://www.tensorflow.org/static/text/tutorials/images/bidirectional.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "We will be using an Embedding layer loaded, followed by a RNN layer, and a linear layer.\n",
    "\n",
    "We will would be using the Clickbait and Web of science dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aajl3628zAkp"
   },
   "source": [
    "### 3.1.1 : Pre-Processing Data \n",
    "\n",
    "load functions for building vocabulary and tokenizing the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8qk1qpnIzCwe",
    "outputId": "5f75fc50-8aaa-4a09-dc2e-f78bcc8ed8d3"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def build_vocabulary(datasets):\n",
    "  for dataset in datasets:\n",
    "    for text in dataset:\n",
    "      yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(build_vocabulary([x_train]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "vocab_wos = build_vocab_from_iterator(build_vocabulary([x_train_wos]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab_wos.set_default_index(vocab[\"<UNK>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EUMc-XzSvVVM"
   },
   "source": [
    "## 3.2 : Classifying Clickbait Dataset using RNN\n",
    "\n",
    "classify the Clickbait train and test dataset using the RNN functions that you have already implemented in 3.\n",
    "\n",
    "An accuracy of more than 85% is acceptable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "JGth1KFuzKMe",
    "outputId": "70e6c739-3d64-4751-b2dd-801931eb967f"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_words = max(map(len, x_train))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "bPd8FJ2ozNsf",
    "outputId": "b1bad498-5727-46ed-ae3a-3f2f2d4a7668"
   },
   "outputs": [],
   "source": [
    "train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18559"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "zlXccqKokN-u",
    "outputId": "bc849b0f-43ad-4783-f8ad-da88656026d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of rnn failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 312, in update_instances\n",
      "    update_instances(old, new, obj.__dict__, visited)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 312, in update_instances\n",
      "    update_instances(old, new, obj.__dict__, visited)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"C:\\Users\\ghoneimm\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 305, in update_instances\n",
      "    if type(obj) is old:\n",
      "KeyboardInterrupt\n",
      "]\n",
      "100%|| 19/19 [00:12<00:00,  1.54it/s]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 7.642385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [00:12<00:00,  1.54it/s]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 2.991242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [00:12<00:00,  1.51it/s]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 1.574596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [00:12<00:00,  1.49it/s]\n",
      "  0%|                                                                                           | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 0.988239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 19/19 [00:12<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 0.693172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = RNN(vocab, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "      X = X.to(device)\n",
    "      Y = Y.to(device)\n",
    "    \n",
    "      outputs = model(X, X_len)\n",
    "      loss = criterion(outputs, Y)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UjopZ85QsEcV",
    "outputId": "bac143d6-28f5-4f83-a18f-b00176d82080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using RNN  : 0.932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "  Y_truth, Y_preds = [],[]\n",
    "  for X, X_len, Y in test_loader:\n",
    "    X = X.to(device)\n",
    "    outputs = model(X, X_len)\n",
    "\n",
    "    Y_truth.append(Y)\n",
    "    Y_preds.append(outputs)\n",
    "\n",
    "  Y_truth = torch.cat(Y_truth)\n",
    "  Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7JXqy4Yzj7R"
   },
   "source": [
    "Run the below cell to save the predictions. You will be required to upload the predictions on gradescope for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "YIoYfQJtzkdX",
    "outputId": "81b2dfae-81e3-4576-d8e9-58e6e6a0647a"
   },
   "outputs": [],
   "source": [
    "preds = F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy()\n",
    "\n",
    "with open('rnn_clickbait.pkl', 'wb') as fp:\n",
    "    pickle.dump(preds, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sW4Am9kvdGA"
   },
   "source": [
    "## 3.3 : Classifying Web of Science Dataset using RNN\n",
    "\n",
    "classify the WoS train and test dataset using the lstm functions implemented in 3.\n",
    "\n",
    "An accuracy of more than 35% is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DPZE5g1uRI_I",
    "outputId": "5b47c0ad-5e17-4424-c482-2d102e746fbe"
   },
   "outputs": [],
   "source": [
    "max_words = max(map(len, x_train_wos))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab_wos(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] \n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1ypsgOIIRUFm",
    "outputId": "6c795bf1-88db-46e4-ec3e-606d7aaf0dfb"
   },
   "outputs": [],
   "source": [
    "train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "195yI5vSvhWr",
    "outputId": "1b605091-1ba2-4735-df9d-3f53477f8403"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [04:04<00:00, 18.83s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 17.465020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:09<00:00, 14.57s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 15.911758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:03<00:00, 14.13s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 15.190116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:02<00:00, 14.02s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 14.551816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:04<00:00, 14.18s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 13.835879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:04<00:00, 14.21s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 5: 12.974420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:00<00:00, 13.90s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 6: 12.280683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:58<00:00, 13.76s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 7: 11.578939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:51<00:00, 13.20s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 8: 10.312908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:57<00:00, 13.66s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 9: 9.603132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:55<00:00, 13.50s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 10: 8.815215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:50<00:00, 13.10s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 11: 7.935928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:02<00:00, 14.02s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 12: 7.399226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:59<00:00, 13.83s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 13: 6.557069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:01<00:00, 13.98s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 14: 5.626970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:04<00:00, 14.17s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 15: 5.244434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:55<00:00, 13.54s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 16: 4.670967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:06<00:00, 14.31s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 17: 4.142456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [03:02<00:00, 14.03s/it]\n",
      "  0%|                                                                                           | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 18: 3.407744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [02:58<00:00, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 19: 3.297573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = RNN(vocab_wos, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "      X = X.to(device)\n",
    "      Y = Y.to(device)\n",
    "      outputs = model(X, X_len)\n",
    "      loss = criterion(outputs, Y)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ltNFDxdyvt-k",
    "outputId": "f9f407e2-4540-4955-c8db-b4b5543e1eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using RNN  : 0.427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "  Y_truth, Y_preds = [],[]\n",
    "  for X, X_len, Y in test_loader:\n",
    "    X = X.to(device)\n",
    "    outputs = model(X, X_len)\n",
    "\n",
    "    Y_truth.append(Y)\n",
    "    Y_preds.append(outputs)\n",
    "\n",
    "  Y_truth = torch.cat(Y_truth)\n",
    "  Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ADcLlGMm0JOZ",
    "outputId": "dc5cba1c-5269-466f-f48c-4ff0b5e9f05b"
   },
   "outputs": [],
   "source": [
    "preds = F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy()\n",
    "\n",
    "with open('rnn_wos.pkl', 'wb') as fp:\n",
    "    pickle.dump(preds, fp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-Np3UUmtFUjd",
    "4TLUiFFR7wlL",
    "dRvybL9rYxcQ",
    "_sW4Am9kvdGA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
